{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 循环神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手工 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons],dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons,n_neurons],dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "H0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "H1 = tf.tanh(tf.matmul(H0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_batch = np.array([[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3]]) # t = 0\n",
    "X1_batch = np.array([[4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9]]) # t = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    H0_val, H1_val = sess.run([H0, H1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[ 0.          0.          0.          0.          0.        ]\n",
      " [-0.98710734 -0.987816    0.2626741  -0.44695795 -0.998247  ]\n",
      " [-0.9999159  -0.99992496  0.49143997 -0.7450718  -0.9999985 ]\n",
      " [-0.9999995  -0.9999997   0.6678964  -0.8942353  -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(H0_val.shape==H1_val.shape)\n",
    "print(H0_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 `static_rnn()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.nn.static_rnn(basic_cell, [X0, X1], dtype=tf.float32)\n",
    "\n",
    "H0, H1 = output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "X0_batch = np.array([[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "X1_batch = np.array([[4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([H0, H1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "    s_val, H0_val, H1_val = sess.run([states,H0,H1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "    output_seqs_val =sess.run([output_seqs], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(s_val == H1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(output_seqs_val[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 `dynamic_rnn()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch = np.array([\n",
    "        [[0, 0, 0], [4, 5, 6]], # instance 1\n",
    "        [[1, 1, 1], [5, 6, 7]], # instance 2\n",
    "        [[2, 2, 2], [6, 7, 8]], # instance 3\n",
    "        [[3, 3, 3], [7, 8, 9]], # instance 4\n",
    "    ])\n",
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "X_batch = np.array([\n",
    "        [[0, 0, 0], [4, 5, 6]], # instance 1\n",
    "        [[1, 1, 1], [5, 6, 7]], # instance 2\n",
    "        [[2, 2, 2], [6, 7, 8]], # instance 3\n",
    "        [[3, 3, 3], [7, 8, 9]], # instance 4\n",
    "    ])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})\n",
    "    states_val = states.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9577261  -0.9951577  -0.99985605 -0.7528284  -0.7155064 ]\n",
      " [-0.9387486  -0.99966097 -0.99998814 -0.48122504 -0.93438   ]\n",
      " [-0.9542085  -0.9999398  -0.9999989  -0.30927062 -0.97431576]\n",
      " [-0.9739977  -0.9999842  -0.9999997  -0.25144023 -0.9872973 ]]\n"
     ]
    }
   ],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9577261  -0.9951577  -0.99985605 -0.7528284  -0.7155064 ]\n",
      " [-0.9387486  -0.99966097 -0.99998814 -0.48122504 -0.93438   ]\n",
      " [-0.9542085  -0.9999398  -0.9999989  -0.30927062 -0.97431576]\n",
      " [-0.9739977  -0.9999842  -0.9999997  -0.25144023 -0.9872973 ]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val[:,1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理变长输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = tf.placeholder(tf.int32, None)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "                                    sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "X_batch = np.array([\n",
    "        # 时间步 0     时间步 1\n",
    "        [[0, 0, 0], [4, 5, 6]], # 实例 1\n",
    "        [[1, 1, 1], [5, 6, 7]], # 实例 2\n",
    "        [[2, 2, 2], [6, 7, 8]], # 实例 3（长度为 1，后面的数据被丢弃）\n",
    "        [[3, 3, 3], [7, 8, 9]], # 实例 4\n",
    "    ])\n",
    "seq_length_batch = np.array([2, 2, 1, 2]) # 实例 3 的长度被设为 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run(\n",
    "        [outputs, states], feed_dict={X: X_batch, seq_length: seq_length_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.          0.          0.          0.          0.        ]\n",
      "  [ 0.9999274   0.78506315 -0.99982464  0.45810056  0.9633542 ]]\n",
      "\n",
      " [[ 0.8261823   0.28237453 -0.6885522   0.02922334  0.45902106]\n",
      "  [ 0.99999136  0.7682828  -0.9999783   0.8550243   0.9970976 ]]\n",
      "\n",
      " [[ 0.9820439   0.523044   -0.9341975   0.05839681  0.7582737 ]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.9982769   0.701771   -0.9875282   0.08747088  0.90299493]\n",
      "  [ 0.9999999   0.94575775 -0.9999997   0.9217818   0.99974984]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9999274   0.78506315 -0.99982464  0.45810056  0.9633542 ]\n",
      " [ 0.99999136  0.7682828  -0.9999783   0.8550243   0.9970976 ]\n",
      " [ 0.9820439   0.523044   -0.9341975   0.05839681  0.7582737 ]\n",
      " [ 0.9999999   0.94575775 -0.9999997   0.9217818   0.99974984]]\n"
     ]
    }
   ],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 循环网络实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "    y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "with tf.name_scope(\"rnn\"):\n",
    "    basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "    outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "    \n",
    "with tf.name_scope(\"fc\"):\n",
    "    logits = tf.layers.dense(states, n_outputs)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                          logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./tmp/data/\")\n",
    "X4 = mnist.test.images\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.95 Test accuracy: 0.9258\n",
      "1 Train accuracy: 0.99 Test accuracy: 0.9384\n",
      "2 Train accuracy: 0.99 Test accuracy: 0.9598\n",
      "3 Train accuracy: 0.93 Test accuracy: 0.9653\n",
      "4 Train accuracy: 0.98 Test accuracy: 0.9649\n",
      "5 Train accuracy: 1.0 Test accuracy: 0.9685\n",
      "6 Train accuracy: 0.98 Test accuracy: 0.9722\n",
      "7 Train accuracy: 0.98 Test accuracy: 0.9662\n",
      "8 Train accuracy: 0.99 Test accuracy: 0.9681\n",
      "9 Train accuracy: 0.96 Test accuracy: 0.9646\n",
      "10 Train accuracy: 1.0 Test accuracy: 0.9731\n",
      "11 Train accuracy: 0.97 Test accuracy: 0.9645\n",
      "12 Train accuracy: 0.98 Test accuracy: 0.977\n",
      "13 Train accuracy: 0.95 Test accuracy: 0.9691\n",
      "14 Train accuracy: 0.97 Test accuracy: 0.9758\n",
      "15 Train accuracy: 1.0 Test accuracy: 0.9774\n",
      "16 Train accuracy: 0.99 Test accuracy: 0.9789\n",
      "17 Train accuracy: 0.95 Test accuracy: 0.9732\n",
      "18 Train accuracy: 0.98 Test accuracy: 0.9714\n",
      "19 Train accuracy: 1.0 Test accuracy: 0.978\n",
      "20 Train accuracy: 0.99 Test accuracy: 0.9738\n",
      "21 Train accuracy: 0.97 Test accuracy: 0.9737\n",
      "22 Train accuracy: 0.98 Test accuracy: 0.9683\n",
      "23 Train accuracy: 0.99 Test accuracy: 0.9674\n",
      "24 Train accuracy: 0.99 Test accuracy: 0.9724\n",
      "25 Train accuracy: 0.99 Test accuracy: 0.9739\n",
      "26 Train accuracy: 0.98 Test accuracy: 0.9763\n",
      "27 Train accuracy: 0.99 Test accuracy: 0.9742\n",
      "28 Train accuracy: 0.99 Test accuracy: 0.9766\n",
      "29 Train accuracy: 0.93 Test accuracy: 0.9783\n",
      "30 Train accuracy: 0.98 Test accuracy: 0.9785\n",
      "31 Train accuracy: 0.97 Test accuracy: 0.9617\n",
      "32 Train accuracy: 1.0 Test accuracy: 0.9814\n",
      "33 Train accuracy: 0.98 Test accuracy: 0.9694\n",
      "34 Train accuracy: 0.99 Test accuracy: 0.9757\n",
      "35 Train accuracy: 1.0 Test accuracy: 0.9783\n",
      "36 Train accuracy: 1.0 Test accuracy: 0.9759\n",
      "37 Train accuracy: 0.98 Test accuracy: 0.9757\n",
      "38 Train accuracy: 0.99 Test accuracy: 0.9717\n",
      "39 Train accuracy: 1.0 Test accuracy: 0.9802\n",
      "40 Train accuracy: 0.99 Test accuracy: 0.9719\n",
      "41 Train accuracy: 0.98 Test accuracy: 0.9741\n",
      "42 Train accuracy: 1.0 Test accuracy: 0.977\n",
      "43 Train accuracy: 0.98 Test accuracy: 0.9772\n",
      "44 Train accuracy: 0.98 Test accuracy: 0.9715\n",
      "45 Train accuracy: 0.99 Test accuracy: 0.9745\n",
      "46 Train accuracy: 0.99 Test accuracy: 0.9788\n",
      "47 Train accuracy: 0.98 Test accuracy: 0.9691\n",
      "48 Train accuracy: 0.98 Test accuracy: 0.9791\n",
      "49 Train accuracy: 1.0 Test accuracy: 0.9786\n",
      "50 Train accuracy: 1.0 Test accuracy: 0.9804\n",
      "51 Train accuracy: 1.0 Test accuracy: 0.9748\n",
      "52 Train accuracy: 0.98 Test accuracy: 0.9732\n",
      "53 Train accuracy: 0.99 Test accuracy: 0.9779\n",
      "54 Train accuracy: 0.98 Test accuracy: 0.9757\n",
      "55 Train accuracy: 1.0 Test accuracy: 0.975\n",
      "56 Train accuracy: 0.99 Test accuracy: 0.9785\n",
      "57 Train accuracy: 0.99 Test accuracy: 0.9727\n",
      "58 Train accuracy: 0.99 Test accuracy: 0.9738\n",
      "59 Train accuracy: 0.98 Test accuracy: 0.9745\n",
      "60 Train accuracy: 0.97 Test accuracy: 0.9742\n",
      "61 Train accuracy: 0.99 Test accuracy: 0.9736\n",
      "62 Train accuracy: 0.97 Test accuracy: 0.9741\n",
      "63 Train accuracy: 0.97 Test accuracy: 0.9757\n",
      "64 Train accuracy: 0.98 Test accuracy: 0.9663\n",
      "65 Train accuracy: 0.98 Test accuracy: 0.9673\n",
      "66 Train accuracy: 0.99 Test accuracy: 0.9761\n",
      "67 Train accuracy: 0.97 Test accuracy: 0.9776\n",
      "68 Train accuracy: 0.97 Test accuracy: 0.9681\n",
      "69 Train accuracy: 0.97 Test accuracy: 0.9702\n",
      "70 Train accuracy: 0.99 Test accuracy: 0.9757\n",
      "71 Train accuracy: 0.99 Test accuracy: 0.9718\n",
      "72 Train accuracy: 1.0 Test accuracy: 0.9777\n",
      "73 Train accuracy: 0.99 Test accuracy: 0.9779\n",
      "74 Train accuracy: 0.99 Test accuracy: 0.9767\n",
      "75 Train accuracy: 0.98 Test accuracy: 0.9714\n",
      "76 Train accuracy: 0.99 Test accuracy: 0.9734\n",
      "77 Train accuracy: 0.98 Test accuracy: 0.9536\n",
      "78 Train accuracy: 0.98 Test accuracy: 0.9711\n",
      "79 Train accuracy: 0.99 Test accuracy: 0.9731\n",
      "80 Train accuracy: 1.0 Test accuracy: 0.9716\n",
      "81 Train accuracy: 0.99 Test accuracy: 0.977\n",
      "82 Train accuracy: 0.98 Test accuracy: 0.9759\n",
      "83 Train accuracy: 0.98 Test accuracy: 0.9747\n",
      "84 Train accuracy: 1.0 Test accuracy: 0.9782\n",
      "85 Train accuracy: 0.98 Test accuracy: 0.971\n",
      "86 Train accuracy: 0.97 Test accuracy: 0.9749\n",
      "87 Train accuracy: 0.98 Test accuracy: 0.9737\n",
      "88 Train accuracy: 0.98 Test accuracy: 0.9711\n",
      "89 Train accuracy: 0.96 Test accuracy: 0.9672\n",
      "90 Train accuracy: 0.98 Test accuracy: 0.9639\n",
      "91 Train accuracy: 0.97 Test accuracy: 0.9728\n",
      "92 Train accuracy: 0.99 Test accuracy: 0.974\n",
      "93 Train accuracy: 0.97 Test accuracy: 0.9693\n",
      "94 Train accuracy: 0.99 Test accuracy: 0.9762\n",
      "95 Train accuracy: 0.99 Test accuracy: 0.9765\n",
      "96 Train accuracy: 0.99 Test accuracy: 0.9664\n",
      "97 Train accuracy: 0.95 Test accuracy: 0.9761\n",
      "98 Train accuracy: 0.97 Test accuracy: 0.9591\n",
      "99 Train accuracy: 1.0 Test accuracy: 0.9738\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.estimator 循环网络实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model_fn(features, labels, mode):\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28])\n",
    "\n",
    "  basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=150)\n",
    "  outputs, states = tf.nn.dynamic_rnn(basic_cell, input_layer, dtype=tf.float32)\n",
    "\n",
    "  logits = tf.layers.dense(states, n_outputs)\n",
    "\n",
    "  predictions = {\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_master': '', '_log_step_count_steps': 100, '_session_config': None, '_service': None, '_is_chief': True, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/mnist_rnn_model', '_num_worker_replicas': 1, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc308251eb8>}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_rnn_model/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.3687696\n",
      "INFO:tensorflow:global_step/sec: 24.9666\n",
      "INFO:tensorflow:step = 101, loss = 2.129938 (4.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6126\n",
      "INFO:tensorflow:step = 201, loss = 2.0482488 (3.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7835\n",
      "INFO:tensorflow:step = 301, loss = 1.682167 (4.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8518\n",
      "INFO:tensorflow:step = 401, loss = 1.6345015 (4.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0067\n",
      "INFO:tensorflow:step = 501, loss = 1.4677069 (3.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0887\n",
      "INFO:tensorflow:step = 601, loss = 1.3966694 (3.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2062\n",
      "INFO:tensorflow:step = 701, loss = 1.2598712 (3.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8255\n",
      "INFO:tensorflow:step = 801, loss = 1.334187 (4.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4618\n",
      "INFO:tensorflow:step = 901, loss = 1.169219 (3.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2039\n",
      "INFO:tensorflow:step = 1001, loss = 1.1926353 (3.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.507\n",
      "INFO:tensorflow:step = 1101, loss = 1.0415267 (3.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5236\n",
      "INFO:tensorflow:step = 1201, loss = 1.0361289 (3.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5191\n",
      "INFO:tensorflow:step = 1301, loss = 1.1661246 (4.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2721\n",
      "INFO:tensorflow:step = 1401, loss = 0.9916299 (3.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1301\n",
      "INFO:tensorflow:step = 1501, loss = 0.91208565 (3.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7996\n",
      "INFO:tensorflow:step = 1601, loss = 0.91600204 (4.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3735\n",
      "INFO:tensorflow:step = 1701, loss = 1.0165799 (3.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4544\n",
      "INFO:tensorflow:step = 1801, loss = 0.88971174 (4.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3692\n",
      "INFO:tensorflow:step = 1901, loss = 0.8353981 (3.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3747\n",
      "INFO:tensorflow:step = 2001, loss = 0.7035246 (3.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2179\n",
      "INFO:tensorflow:step = 2101, loss = 0.80916286 (3.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1727\n",
      "INFO:tensorflow:step = 2201, loss = 0.81937146 (3.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0973\n",
      "INFO:tensorflow:step = 2301, loss = 0.81906 (3.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2931\n",
      "INFO:tensorflow:step = 2401, loss = 0.67320114 (3.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.279\n",
      "INFO:tensorflow:step = 2501, loss = 0.7678447 (3.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4455\n",
      "INFO:tensorflow:step = 2601, loss = 0.6572154 (3.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3615\n",
      "INFO:tensorflow:step = 2701, loss = 0.6948619 (3.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4744\n",
      "INFO:tensorflow:step = 2801, loss = 0.6943488 (3.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5054\n",
      "INFO:tensorflow:step = 2901, loss = 0.70896894 (3.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3564\n",
      "INFO:tensorflow:step = 3001, loss = 0.80705464 (3.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1451\n",
      "INFO:tensorflow:step = 3101, loss = 0.6987097 (3.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2361\n",
      "INFO:tensorflow:step = 3201, loss = 0.58760303 (3.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3241\n",
      "INFO:tensorflow:step = 3301, loss = 0.7637637 (3.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3381\n",
      "INFO:tensorflow:step = 3401, loss = 0.57121986 (3.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2363\n",
      "INFO:tensorflow:step = 3501, loss = 0.59715474 (3.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1481\n",
      "INFO:tensorflow:step = 3601, loss = 0.6039982 (3.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0683\n",
      "INFO:tensorflow:step = 3701, loss = 0.4396096 (3.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.445\n",
      "INFO:tensorflow:step = 3801, loss = 0.61597484 (3.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2143\n",
      "INFO:tensorflow:step = 3901, loss = 0.54653466 (3.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2352\n",
      "INFO:tensorflow:step = 4001, loss = 0.5386069 (3.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2625\n",
      "INFO:tensorflow:step = 4101, loss = 0.5889459 (3.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4334\n",
      "INFO:tensorflow:step = 4201, loss = 0.44613525 (3.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2764\n",
      "INFO:tensorflow:step = 4301, loss = 0.49610955 (3.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4896\n",
      "INFO:tensorflow:step = 4401, loss = 0.47266218 (3.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9172\n",
      "INFO:tensorflow:step = 4501, loss = 0.43187407 (4.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2951\n",
      "INFO:tensorflow:step = 4601, loss = 0.5921119 (3.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3383\n",
      "INFO:tensorflow:step = 4701, loss = 0.5703028 (3.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6788\n",
      "INFO:tensorflow:step = 4801, loss = 0.36265966 (4.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2524\n",
      "INFO:tensorflow:step = 4901, loss = 0.47857937 (3.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2431\n",
      "INFO:tensorflow:step = 5001, loss = 0.39877635 (3.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4202\n",
      "INFO:tensorflow:step = 5101, loss = 0.55121976 (3.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2213\n",
      "INFO:tensorflow:step = 5201, loss = 0.38935682 (3.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8197\n",
      "INFO:tensorflow:step = 5301, loss = 0.41891646 (4.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3462\n",
      "INFO:tensorflow:step = 5401, loss = 0.31874126 (3.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2683\n",
      "INFO:tensorflow:step = 5501, loss = 0.45192686 (3.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.239\n",
      "INFO:tensorflow:step = 5601, loss = 0.24160664 (3.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4075\n",
      "INFO:tensorflow:step = 5701, loss = 0.4362404 (3.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1898\n",
      "INFO:tensorflow:step = 5801, loss = 0.28228614 (3.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0541\n",
      "INFO:tensorflow:step = 5901, loss = 0.2598106 (3.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2027\n",
      "INFO:tensorflow:step = 6001, loss = 0.43812954 (3.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4356\n",
      "INFO:tensorflow:step = 6101, loss = 0.41174948 (3.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2822\n",
      "INFO:tensorflow:step = 6201, loss = 0.3867535 (3.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.171\n",
      "INFO:tensorflow:step = 6301, loss = 0.40205717 (3.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4066\n",
      "INFO:tensorflow:step = 6401, loss = 0.38886604 (3.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4534\n",
      "INFO:tensorflow:step = 6501, loss = 0.3194674 (3.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1508\n",
      "INFO:tensorflow:step = 6601, loss = 0.39477482 (3.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1648\n",
      "INFO:tensorflow:step = 6701, loss = 0.20259102 (3.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3104\n",
      "INFO:tensorflow:step = 6801, loss = 0.42531627 (3.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1595\n",
      "INFO:tensorflow:step = 6901, loss = 0.4512577 (3.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2935\n",
      "INFO:tensorflow:step = 7001, loss = 0.2881338 (3.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4542\n",
      "INFO:tensorflow:step = 7101, loss = 0.3647683 (3.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2314\n",
      "INFO:tensorflow:step = 7201, loss = 0.3237199 (3.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4358\n",
      "INFO:tensorflow:step = 7301, loss = 0.426079 (3.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 7401, loss = 0.29265976 (3.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1972\n",
      "INFO:tensorflow:step = 7501, loss = 0.33486122 (3.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3579\n",
      "INFO:tensorflow:step = 7601, loss = 0.27511376 (3.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6245\n",
      "INFO:tensorflow:step = 7701, loss = 0.47377288 (4.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8572\n",
      "INFO:tensorflow:step = 7801, loss = 0.30049488 (4.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1435\n",
      "INFO:tensorflow:step = 7901, loss = 0.3639042 (3.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3183\n",
      "INFO:tensorflow:step = 8001, loss = 0.2357262 (3.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3166\n",
      "INFO:tensorflow:step = 8101, loss = 0.2941084 (3.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3183\n",
      "INFO:tensorflow:step = 8201, loss = 0.3178193 (3.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1629\n",
      "INFO:tensorflow:step = 8301, loss = 0.41584778 (3.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1618\n",
      "INFO:tensorflow:step = 8401, loss = 0.28155497 (3.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1191\n",
      "INFO:tensorflow:step = 8501, loss = 0.31284398 (3.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1341\n",
      "INFO:tensorflow:step = 8601, loss = 0.28861386 (3.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.28\n",
      "INFO:tensorflow:step = 8701, loss = 0.16159801 (3.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3476\n",
      "INFO:tensorflow:step = 8801, loss = 0.3698787 (3.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9623\n",
      "INFO:tensorflow:step = 8901, loss = 0.20417579 (4.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2514\n",
      "INFO:tensorflow:step = 9001, loss = 0.22288853 (3.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9365\n",
      "INFO:tensorflow:step = 9101, loss = 0.20367728 (4.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0435\n",
      "INFO:tensorflow:step = 9201, loss = 0.22849205 (3.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2409\n",
      "INFO:tensorflow:step = 9301, loss = 0.37707254 (3.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3918\n",
      "INFO:tensorflow:step = 9401, loss = 0.118781336 (3.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.255\n",
      "INFO:tensorflow:step = 9501, loss = 0.39299065 (3.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1317\n",
      "INFO:tensorflow:step = 9601, loss = 0.30306646 (3.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1407\n",
      "INFO:tensorflow:step = 9701, loss = 0.2690176 (3.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0013\n",
      "INFO:tensorflow:step = 9801, loss = 0.22096334 (4.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1363\n",
      "INFO:tensorflow:step = 9901, loss = 0.55365926 (3.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3688\n",
      "INFO:tensorflow:step = 10001, loss = 0.21346855 (3.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2313\n",
      "INFO:tensorflow:step = 10101, loss = 0.34670156 (3.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1924\n",
      "INFO:tensorflow:step = 10201, loss = 0.23165178 (3.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0069\n",
      "INFO:tensorflow:step = 10301, loss = 0.24267381 (3.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2872\n",
      "INFO:tensorflow:step = 10401, loss = 0.22900003 (3.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1827\n",
      "INFO:tensorflow:step = 10501, loss = 0.22942717 (3.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2877\n",
      "INFO:tensorflow:step = 10601, loss = 0.23312114 (3.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.528\n",
      "INFO:tensorflow:step = 10701, loss = 0.19544853 (4.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2023\n",
      "INFO:tensorflow:step = 10801, loss = 0.25551912 (3.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3562\n",
      "INFO:tensorflow:step = 10901, loss = 0.20231271 (3.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2381\n",
      "INFO:tensorflow:step = 11001, loss = 0.35826945 (3.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3084\n",
      "INFO:tensorflow:step = 11101, loss = 0.0684593 (3.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2499\n",
      "INFO:tensorflow:step = 11201, loss = 0.22817178 (3.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3698\n",
      "INFO:tensorflow:step = 11301, loss = 0.30969796 (3.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4732\n",
      "INFO:tensorflow:step = 11401, loss = 0.21168841 (3.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2059\n",
      "INFO:tensorflow:step = 11501, loss = 0.18989967 (3.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4571\n",
      "INFO:tensorflow:step = 11601, loss = 0.29254293 (3.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3658\n",
      "INFO:tensorflow:step = 11701, loss = 0.19922519 (3.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2634\n",
      "INFO:tensorflow:step = 11801, loss = 0.15626787 (3.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3477\n",
      "INFO:tensorflow:step = 11901, loss = 0.30229172 (3.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1232\n",
      "INFO:tensorflow:step = 12001, loss = 0.29480365 (3.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0038\n",
      "INFO:tensorflow:step = 12101, loss = 0.17821369 (3.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2666\n",
      "INFO:tensorflow:step = 12201, loss = 0.2266023 (3.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3767\n",
      "INFO:tensorflow:step = 12301, loss = 0.26244068 (3.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2397\n",
      "INFO:tensorflow:step = 12401, loss = 0.17622985 (3.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1674\n",
      "INFO:tensorflow:step = 12501, loss = 0.2286116 (3.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2049\n",
      "INFO:tensorflow:step = 12601, loss = 0.17380458 (3.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5773\n",
      "INFO:tensorflow:step = 12701, loss = 0.26104444 (3.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1208\n",
      "INFO:tensorflow:step = 12801, loss = 0.12975828 (3.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4617\n",
      "INFO:tensorflow:step = 12901, loss = 0.12859474 (3.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3942\n",
      "INFO:tensorflow:step = 13001, loss = 0.2880931 (3.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1979\n",
      "INFO:tensorflow:step = 13101, loss = 0.14773838 (3.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4145\n",
      "INFO:tensorflow:step = 13201, loss = 0.23895349 (3.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4116\n",
      "INFO:tensorflow:step = 13301, loss = 0.08952694 (3.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1711\n",
      "INFO:tensorflow:step = 13401, loss = 0.15487823 (3.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3248\n",
      "INFO:tensorflow:step = 13501, loss = 0.16510172 (3.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0427\n",
      "INFO:tensorflow:step = 13601, loss = 0.15542524 (3.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7671\n",
      "INFO:tensorflow:step = 13701, loss = 0.22098881 (4.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2761\n",
      "INFO:tensorflow:step = 13801, loss = 0.242276 (3.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2358\n",
      "INFO:tensorflow:step = 13901, loss = 0.19085686 (3.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2375\n",
      "INFO:tensorflow:step = 14001, loss = 0.33560172 (3.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.278\n",
      "INFO:tensorflow:step = 14101, loss = 0.20240325 (3.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3153\n",
      "INFO:tensorflow:step = 14201, loss = 0.18661992 (3.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3309\n",
      "INFO:tensorflow:step = 14301, loss = 0.22883426 (3.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2815\n",
      "INFO:tensorflow:step = 14401, loss = 0.09282397 (3.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3048\n",
      "INFO:tensorflow:step = 14501, loss = 0.21292636 (3.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1249\n",
      "INFO:tensorflow:step = 14601, loss = 0.14211375 (3.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5361\n",
      "INFO:tensorflow:step = 14701, loss = 0.14357951 (3.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2009\n",
      "INFO:tensorflow:step = 14801, loss = 0.28289777 (3.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1281\n",
      "INFO:tensorflow:step = 14901, loss = 0.17529024 (3.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9841\n",
      "INFO:tensorflow:step = 15001, loss = 0.25023913 (4.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2411\n",
      "INFO:tensorflow:step = 15101, loss = 0.1826196 (3.962 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15108 into /tmp/mnist_rnn_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 24.8255\n",
      "INFO:tensorflow:step = 15201, loss = 0.21913439 (4.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4984\n",
      "INFO:tensorflow:step = 15301, loss = 0.18545185 (3.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0964\n",
      "INFO:tensorflow:step = 15401, loss = 0.23702073 (3.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 15501, loss = 0.0618818 (4.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2271\n",
      "INFO:tensorflow:step = 15601, loss = 0.19846804 (3.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2996\n",
      "INFO:tensorflow:step = 15701, loss = 0.14752124 (3.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0879\n",
      "INFO:tensorflow:step = 15801, loss = 0.16215582 (3.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1228\n",
      "INFO:tensorflow:step = 15901, loss = 0.168251 (3.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5264\n",
      "INFO:tensorflow:step = 16001, loss = 0.22507143 (4.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7463\n",
      "INFO:tensorflow:step = 16101, loss = 0.2095325 (4.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1559\n",
      "INFO:tensorflow:step = 16201, loss = 0.22724357 (4.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1971\n",
      "INFO:tensorflow:step = 16301, loss = 0.25522813 (3.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8618\n",
      "INFO:tensorflow:step = 16401, loss = 0.14047818 (4.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0482\n",
      "INFO:tensorflow:step = 16501, loss = 0.2032221 (3.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1432\n",
      "INFO:tensorflow:step = 16601, loss = 0.07291494 (3.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4221\n",
      "INFO:tensorflow:step = 16701, loss = 0.3381648 (4.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1006\n",
      "INFO:tensorflow:step = 16801, loss = 0.15376018 (3.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0749\n",
      "INFO:tensorflow:step = 16901, loss = 0.13052481 (3.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0578\n",
      "INFO:tensorflow:step = 17001, loss = 0.1279627 (3.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8201\n",
      "INFO:tensorflow:step = 17101, loss = 0.19012181 (4.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4141\n",
      "INFO:tensorflow:step = 17201, loss = 0.21554138 (4.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2071\n",
      "INFO:tensorflow:step = 17301, loss = 0.19733635 (3.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7386\n",
      "INFO:tensorflow:step = 17401, loss = 0.17562413 (4.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1452\n",
      "INFO:tensorflow:step = 17501, loss = 0.187652 (3.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0107\n",
      "INFO:tensorflow:step = 17601, loss = 0.18225862 (3.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2407\n",
      "INFO:tensorflow:step = 17701, loss = 0.10699314 (3.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4239\n",
      "INFO:tensorflow:step = 17801, loss = 0.30149424 (4.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7755\n",
      "INFO:tensorflow:step = 17901, loss = 0.19170631 (4.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4713\n",
      "INFO:tensorflow:step = 18001, loss = 0.18445697 (3.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1565\n",
      "INFO:tensorflow:step = 18101, loss = 0.086288005 (3.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2071\n",
      "INFO:tensorflow:step = 18201, loss = 0.1898693 (3.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.337\n",
      "INFO:tensorflow:step = 18301, loss = 0.0991306 (3.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.905\n",
      "INFO:tensorflow:step = 18401, loss = 0.19362755 (4.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6525\n",
      "INFO:tensorflow:step = 18501, loss = 0.12719509 (4.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1046\n",
      "INFO:tensorflow:step = 18601, loss = 0.23143893 (3.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.987\n",
      "INFO:tensorflow:step = 18701, loss = 0.18259491 (4.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3281\n",
      "INFO:tensorflow:step = 18801, loss = 0.06333905 (3.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3305\n",
      "INFO:tensorflow:step = 18901, loss = 0.2198283 (3.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1341\n",
      "INFO:tensorflow:step = 19001, loss = 0.14850232 (3.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7932\n",
      "INFO:tensorflow:step = 19101, loss = 0.09347522 (4.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8649\n",
      "INFO:tensorflow:step = 19201, loss = 0.1705556 (4.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3717\n",
      "INFO:tensorflow:step = 19301, loss = 0.073594995 (4.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7631\n",
      "INFO:tensorflow:step = 19401, loss = 0.19926834 (4.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0279\n",
      "INFO:tensorflow:step = 19501, loss = 0.09815779 (3.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.179\n",
      "INFO:tensorflow:step = 19601, loss = 0.17907985 (4.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.735\n",
      "INFO:tensorflow:step = 19701, loss = 0.113041036 (4.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0145\n",
      "INFO:tensorflow:step = 19801, loss = 0.0933102 (3.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8304\n",
      "INFO:tensorflow:step = 19901, loss = 0.108246334 (4.027 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/mnist_rnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.20419767.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-03-08:10:41\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_rnn_model/model.ckpt-20000\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-03-08:10:42\n",
      "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.9511, global_step = 20000, loss = 0.17191736\n",
      "{'accuracy': 0.9511, 'global_step': 20000, 'loss': 0.17191736}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./tmp/data/\")\n",
    "train_data = mnist.train.images  # 返回的是 np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images  # 返回的是 np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "# 创建 Estimator 对象，模型函数使用 rnn_model_fn，模型保存在 model_dir 目录中\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=rnn_model_fn, model_dir=\"/tmp/mnist_rnn_model\")\n",
    "\n",
    "# 训练模型\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data}, y=train_labels, batch_size=100,\n",
    "    num_epochs=None, shuffle=True)\n",
    "mnist_classifier.train( input_fn=train_input_fn, steps=20000)\n",
    "\n",
    "# 评估模型并打印评估结果\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data}, y=eval_labels, num_epochs=1, shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras 循环网络实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.datasets import mnist\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy\n",
    "from tensorflow.python.keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "steps = 28\n",
    "input_size = 28\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], steps, input_size)\n",
    "x_test = x_test.reshape(x_test.shape[0], steps, input_size)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# 将 y_train 和 y_test 转换成 one-hot 编码\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(\n",
    "    units=150,\n",
    "    batch_input_shape=(None, steps, input_size)\n",
    "    ))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 28s 462us/step - loss: 0.5202 - acc: 0.8463 - val_loss: 0.2209 - val_acc: 0.9364\n",
      "\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 27s 456us/step - loss: 0.2017 - acc: 0.9419 - val_loss: 0.1920 - val_acc: 0.9443\n",
      "\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 28s 461us/step - loss: 0.1585 - acc: 0.9540 - val_loss: 0.1608 - val_acc: 0.9523\n",
      "\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 27s 457us/step - loss: 0.1350 - acc: 0.9607 - val_loss: 0.1271 - val_acc: 0.9639\n",
      "\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 28s 463us/step - loss: 0.1200 - acc: 0.9653 - val_loss: 0.1216 - val_acc: 0.9617\n",
      "\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 28s 463us/step - loss: 0.1068 - acc: 0.9690 - val_loss: 0.1355 - val_acc: 0.9605\n",
      "\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 27s 457us/step - loss: 0.0990 - acc: 0.9706 - val_loss: 0.1119 - val_acc: 0.9670\n",
      "\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 27s 457us/step - loss: 0.0902 - acc: 0.9723 - val_loss: 0.0953 - val_acc: 0.9714\n",
      "\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 27s 453us/step - loss: 0.0838 - acc: 0.9754 - val_loss: 0.1024 - val_acc: 0.9689\n",
      "\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 28s 459us/step - loss: 0.0777 - acc: 0.9763 - val_loss: 0.0898 - val_acc: 0.9727\n",
      "\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 28s 460us/step - loss: 0.0720 - acc: 0.9786 - val_loss: 0.0972 - val_acc: 0.9720\n",
      "\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 28s 460us/step - loss: 0.0690 - acc: 0.9790 - val_loss: 0.0812 - val_acc: 0.9756\n",
      "\n",
      "Test loss: 0.08116694699320942\n",
      "Test accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    units=150,\n",
    "    batch_input_shape=(None, steps, input_size)\n",
    "    ))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 113s 2ms/step - loss: 0.7904 - acc: 0.7341 - val_loss: 0.3037 - val_acc: 0.9018\n",
      "\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 112s 2ms/step - loss: 0.1804 - acc: 0.9447 - val_loss: 0.1340 - val_acc: 0.9570\n",
      "\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 112s 2ms/step - loss: 0.1188 - acc: 0.9644 - val_loss: 0.1119 - val_acc: 0.9645\n",
      "\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 114s 2ms/step - loss: 0.0955 - acc: 0.9704 - val_loss: 0.1131 - val_acc: 0.9630\n",
      "\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 115s 2ms/step - loss: 0.0805 - acc: 0.9756 - val_loss: 0.0812 - val_acc: 0.9741\n",
      "\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 117s 2ms/step - loss: 0.0695 - acc: 0.9789 - val_loss: 0.0776 - val_acc: 0.9753\n",
      "\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 121s 2ms/step - loss: 0.0601 - acc: 0.9816 - val_loss: 0.0667 - val_acc: 0.9782\n",
      "\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 120s 2ms/step - loss: 0.0541 - acc: 0.9832 - val_loss: 0.0674 - val_acc: 0.9780\n",
      "\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 115s 2ms/step - loss: 0.0475 - acc: 0.9848 - val_loss: 0.0683 - val_acc: 0.9772\n",
      "\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 117s 2ms/step - loss: 0.0422 - acc: 0.9866 - val_loss: 0.0556 - val_acc: 0.9814\n",
      "\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 114s 2ms/step - loss: 0.0382 - acc: 0.9884 - val_loss: 0.0572 - val_acc: 0.9814\n",
      "\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 113s 2ms/step - loss: 0.0346 - acc: 0.9895 - val_loss: 0.0541 - val_acc: 0.9834\n",
      "\n",
      "Test loss: 0.05405718424441293\n",
      "Test accuracy: 0.9834\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU 网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(\n",
    "    units=150,\n",
    "    batch_input_shape=(None, steps, input_size)\n",
    "    ))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 90s 2ms/step - loss: 0.9143 - acc: 0.6826 - val_loss: 0.3736 - val_acc: 0.8854\n",
      "\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 87s 1ms/step - loss: 0.2580 - acc: 0.9234 - val_loss: 0.1899 - val_acc: 0.9419\n",
      "\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 89s 1ms/step - loss: 0.1761 - acc: 0.9471 - val_loss: 0.1641 - val_acc: 0.9508\n",
      "\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 86s 1ms/step - loss: 0.1428 - acc: 0.9580 - val_loss: 0.1365 - val_acc: 0.9585\n",
      "\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 87s 1ms/step - loss: 0.1219 - acc: 0.9637 - val_loss: 0.1096 - val_acc: 0.9678\n",
      "\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 87s 1ms/step - loss: 0.1048 - acc: 0.9691 - val_loss: 0.1208 - val_acc: 0.9639\n",
      "\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 86s 1ms/step - loss: 0.0924 - acc: 0.9727 - val_loss: 0.0913 - val_acc: 0.9734\n",
      "\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 87s 1ms/step - loss: 0.0822 - acc: 0.9755 - val_loss: 0.0881 - val_acc: 0.9728\n",
      "\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 87s 1ms/step - loss: 0.0735 - acc: 0.9776 - val_loss: 0.0841 - val_acc: 0.9745\n",
      "\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 88s 1ms/step - loss: 0.0666 - acc: 0.9794 - val_loss: 0.0753 - val_acc: 0.9793\n",
      "\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 88s 1ms/step - loss: 0.0601 - acc: 0.9813 - val_loss: 0.0763 - val_acc: 0.9767\n",
      "\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 88s 1ms/step - loss: 0.0546 - acc: 0.9835 - val_loss: 0.0671 - val_acc: 0.9787\n",
      "\n",
      "Test loss: 0.06714096867516636\n",
      "Test accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
